import requests
import csv
import time
from bs4 import BeautifulSoup

def fetch_results(page=1):
    url = f"https://www.baloto.com/resultados?page={page}"
    resp = requests.get(url)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    # localizar tabla de resultados
    rows = []
    for tr in soup.select("table tbody tr"):
        cols = [td.get_text(strip=True) for td in tr.find_all("td")]
        if len(cols) >= 3:
            # asumiendo formato: Sorteo | Fecha | Resultado
            sorteo = cols[0]
            fecha = cols[1]
            resultado = cols[2]
            rows.append((sorteo, fecha, resultado))
    return rows

def save_to_csv(filename, data):
    with open(filename, mode="w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Sorteo", "Fecha", "Resultado"])
        for row in data:
            writer.writerow(row)

def main(max_pages=100):
    all_results = []
    for page in range(1, max_pages+1):
        try:
            rows = fetch_results(page)
            if not rows:
                break
            all_results.extend(rows)
            print(f"Página {page} descargada: {len(rows)} resultados")
            time.sleep(1)  # para respetar servidor
        except Exception as e:
            print(f"Error en página {page}: {e}")
            break
    save_to_csv("baloto_historico.csv", all_results)
    print(f"Guardados {len(all_results)} registros en baloto_historico.csv")

if __name__ == "__main__":
    main(max_pages=100)
